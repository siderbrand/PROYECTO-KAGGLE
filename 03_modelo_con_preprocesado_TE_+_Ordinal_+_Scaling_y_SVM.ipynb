{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siderbrand/PROYECTO-KAGGLE/blob/main/03_modelo_con_preprocesado_TE_%2B_Ordinal_%2B_Scaling_y_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><img alt=\"udeA logo\" height=\"150px\" src=\"https://github.com/freddyduitama/images/blob/master/logo.png?raw=true\"></p><h1><font color='0B5345'> <center>\n",
        "\n",
        "</center></font></h1>\n",
        "<center>\n",
        "INTRODUCCION A LA INTELIGENIA ARTIFICIAL\n",
        "\n",
        " </center></font></h1>\n",
        "<h2><font color='0B5345'> <center>\n",
        "PROYECTO KAGGLE</center></font></h2>\n",
        "<font  face=\"Courier New\" size=\"3\">\n",
        "\n",
        "<p3><center><b><font color='0B5345' face=\"Lucida Calligraphy,Comic Sans MS,Lucida Console\" size=\"5\">Universidad de Antioquia</font></b> </center></p3>\n",
        "\n",
        "<p3><center><b><font> Juan Andres Toro Acevedo - Bioingenieria\n",
        "<p3><center><b><font> Eliana María Brand Agudelo - Ingenieria en Sistemas\n",
        "<p3><center><b><font> Claudia María Rocha Hernández- Ingenieria en Sistemas"
      ],
      "metadata": {
        "id": "yg7yEWQzbCu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalacion de librerias"
      ],
      "metadata": {
        "id": "bu0UJ3N4kll8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRAVapTBa2nM"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn pandas joblib tqdm lightgbm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montar en Drive"
      ],
      "metadata": {
        "id": "e9LzSmtLkoD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grpcWQV1bVxt",
        "outputId": "1ffbf858-eda7-4147-d4c5-d40ca7dfe58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar la ruta para el archivo preprocesado y el path para cargar el output"
      ],
      "metadata": {
        "id": "HSQoPhFSkq-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/Introduccion IA/cleaned_data.csv\"\n",
        "OUTPUT_MODEL = \"/content/drive/MyDrive/Colab Notebooks/Introduccion IA/modelo_svm_colab.joblib\"\n"
      ],
      "metadata": {
        "id": "FHdbGQrWbLyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports necesarios"
      ],
      "metadata": {
        "id": "PNNRdScNkyHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "fePr8NkRb7IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Encoding K-Fold\n"
      ],
      "metadata": {
        "id": "L7USzcU_k0A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def target_encode_kfold_train(X_train, y_train, cols, n_splits=5, random_state=42):\n",
        "    X_train = X_train.copy()\n",
        "    mappings = {}\n",
        "    if len(cols) == 0:\n",
        "        return X_train, mappings\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    for c in cols:\n",
        "        vals = X_train[c].astype(str).fillna('')\n",
        "        oof = pd.Series(index=X_train.index, dtype=float)\n",
        "\n",
        "        codes, uniques = pd.factorize(pd.Series(y_train).reset_index(drop=True))\n",
        "        y_arr = np.array(codes)\n",
        "        prior = float(np.mean(y_arr))\n",
        "\n",
        "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
        "            train_vals = vals.iloc[train_idx]\n",
        "            train_y = y_arr[train_idx]\n",
        "\n",
        "            stats = pd.DataFrame({\n",
        "                'val': train_vals,\n",
        "                'y': train_y\n",
        "            }).groupby('val')['y'].agg(['mean', 'count'])\n",
        "\n",
        "            k = 5.0\n",
        "            smoothed = ((stats['mean'] * stats['count']) + prior * k) / (stats['count'] + k)\n",
        "            mapped = vals.iloc[val_idx].map(smoothed).fillna(prior)\n",
        "            oof.iloc[val_idx] = mapped\n",
        "\n",
        "        full_stats = pd.DataFrame({\n",
        "            'val': vals,\n",
        "            'y': y_arr\n",
        "        }).groupby('val')['y'].agg(['mean', 'count'])\n",
        "\n",
        "        k = 5.0\n",
        "        full_smoothed = ((full_stats['mean'] * full_stats['count']) +\n",
        "                         prior * k) / (full_stats['count'] + k)\n",
        "\n",
        "        mappings[c] = {\n",
        "            'mapping': full_smoothed.to_dict(),\n",
        "            'global_mean': float(prior),\n",
        "            'label_map': {int(i): v for i, v in enumerate(uniques)}\n",
        "        }\n",
        "\n",
        "        X_train[c + '_te'] = oof.fillna(prior)\n",
        "\n",
        "    return X_train, mappings\n"
      ],
      "metadata": {
        "id": "drfj_N6JcBFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funcion para aplicar target encoding"
      ],
      "metadata": {
        "id": "qf42mYMJk7Rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_te_to_df(X, mappings):\n",
        "    X = X.copy()\n",
        "    for c, info in mappings.items():\n",
        "        if c not in X.columns:\n",
        "            continue\n",
        "        mapping = {str(k): float(v) for k, v in info['mapping'].items()}\n",
        "        gmean = info['global_mean']\n",
        "\n",
        "        X[c + '_te'] = X[c].astype(str).map(mapping).fillna(gmean).astype(float)\n",
        "\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "i8bC8cuqcDRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construccion del Pipeline"
      ],
      "metadata": {
        "id": "EWNJcZuQk-_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_pipeline(X_sample, model_choice='sgd'):\n",
        "    numeric_cols = X_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_cols = X_sample.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    if len(categorical_cols) > 0:\n",
        "        X_sample[categorical_cols] = X_sample[categorical_cols].astype(str).fillna('')\n",
        "\n",
        "    num_pipe = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median'))\n",
        "    ])\n",
        "\n",
        "    ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "\n",
        "    cat_pipe = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='')),\n",
        "        ('ord', ord_enc)\n",
        "    ])\n",
        "\n",
        "    preproc = ColumnTransformer([\n",
        "        ('num', num_pipe, numeric_cols),\n",
        "        ('cat', cat_pipe, categorical_cols)\n",
        "    ], remainder='drop')\n",
        "\n",
        "    model_choice = model_choice.lower()\n",
        "\n",
        "    if model_choice == 'sgd':\n",
        "        base = SGDClassifier(max_iter=1000, tol=1e-3, class_weight='balanced')\n",
        "        clf = CalibratedClassifierCV(base, cv=3)\n",
        "        pipe = Pipeline([\n",
        "            ('preproc', preproc),\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('clf', clf)\n",
        "        ])\n",
        "\n",
        "    elif model_choice == 'logreg':\n",
        "        base = LogisticRegression(\n",
        "            solver='saga', multi_class='multinomial',\n",
        "            max_iter=1000, class_weight='balanced'\n",
        "        )\n",
        "        pipe = Pipeline([\n",
        "            ('preproc', preproc),\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('clf', base)\n",
        "        ])\n",
        "\n",
        "    elif model_choice == 'lgbm':\n",
        "        base = LGBMClassifier(objective='multiclass')\n",
        "        pipe = Pipeline([\n",
        "            ('preproc', preproc),\n",
        "            ('clf', base)\n",
        "        ])\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Modelo no soportado:\", model_choice)\n",
        "\n",
        "    return pipe\n"
      ],
      "metadata": {
        "id": "JJgWrvobcKxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = \"RENDIMIENTO_GLOBAL\"\n",
        "USE_TE = True\n",
        "MODEL = \"sgd\"                     # sgd | logreg | lgbm\n",
        "N_ITER = 30\n",
        "N_JOBS = 2\n",
        "TEST_SIZE = 0.2\n",
        "TE_COLS = 5\n",
        "RANDOM_STATE = 42\n"
      ],
      "metadata": {
        "id": "j24VqneAcNwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar dataset y preparar el target encoding"
      ],
      "metadata": {
        "id": "xwQrT9pXlHsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Dataset cargado:\", df.shape)\n",
        "\n",
        "df = df.dropna(subset=[TARGET])\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "te_mappings = {}\n",
        "\n",
        "if USE_TE:\n",
        "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    cat_cols = sorted(cat_cols, key=lambda c: X_train[c].nunique(), reverse=True)\n",
        "    te_cols = [c for c in cat_cols if X_train[c].nunique() > 3][:TE_COLS]\n",
        "\n",
        "    print(\"TE aplicado en:\", te_cols)\n",
        "\n",
        "    X_train, te_mappings = target_encode_kfold_train(X_train, y_train, te_cols)\n",
        "    X_test = apply_te_to_df(X_test, te_mappings)\n",
        "\n",
        "    # Frequency Encoding\n",
        "    for c in cat_cols:\n",
        "        freq_map = X_train[c].astype(str).value_counts(normalize=True).to_dict()\n",
        "        X_train[c + \"_freq\"] = X_train[c].astype(str).map(freq_map).fillna(0.0)\n",
        "        X_test[c + \"_freq\"] = X_test[c].astype(str).map(freq_map).fillna(0.0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qFLbVdmcUAj",
        "outputId": "f6bf1876-c59c-447c-c91f-f77312fcc112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cargado: (692500, 19)\n",
            "Train: (554000, 18) Test: (138500, 18)\n",
            "TE aplicado en: ['E_PRGM_ACADEMICO', 'E_PRGM_DEPARTAMENTO']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construccion del pipelinee y RandomizedSearchCV"
      ],
      "metadata": {
        "id": "9wkjMWImlK9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = build_pipeline(X_train.head(1000), model_choice=MODEL)\n",
        "\n",
        "if MODEL == 'sgd':\n",
        "    param_dist = {\n",
        "        'clf__estimator__loss': ['hinge', 'log_loss'],\n",
        "        'clf__estimator__penalty': ['l2', 'l1', 'elasticnet'],\n",
        "        'clf__estimator__alpha': [1e-4, 1e-3, 1e-2],\n",
        "        'clf__estimator__eta0': [0.0, 1e-3],\n",
        "    }\n",
        "\n",
        "elif MODEL == 'logreg':\n",
        "    param_dist = {\n",
        "        'clf__C': [0.01, 0.1, 1.0, 5.0],\n",
        "        'clf__penalty': ['l2', 'elasticnet'],\n",
        "        'clf__l1_ratio': [0.0, 0.15, 0.5],\n",
        "    }\n",
        "\n",
        "elif MODEL == 'lgbm':\n",
        "    param_dist = {\n",
        "        'clf__n_estimators': [100, 300, 600],\n",
        "        'clf__learning_rate': [0.01, 0.05, 0.1],\n",
        "        'clf__max_depth': [4, 6, 8],\n",
        "        'clf__num_leaves': [31, 50, 100],\n",
        "        'clf__subsample': [0.7, 0.8, 1.0],\n",
        "        'clf__colsample_bytree': [0.7, 0.8, 1.0],\n",
        "    }\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=N_ITER,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=N_JOBS,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Iniciando RandomizedSearchCV...\")\n",
        "rs.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", rs.best_params_)\n",
        "print(\"Best CV score:\", rs.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5CtsIVhcaiA",
        "outputId": "a007e37d-3af2-4742-8002-fe27e4ba14bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3860950996.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_sample[categorical_cols] = X_sample[categorical_cols].astype(str).fillna('')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando RandomizedSearchCV...\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
            "Best params: {'clf__estimator__penalty': 'l2', 'clf__estimator__loss': 'log_loss', 'clf__estimator__eta0': 0.001, 'clf__estimator__alpha': 0.001}\n",
            "Best CV score: 0.4044169659835524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluacion del mejor modelo"
      ],
      "metadata": {
        "id": "l4Pgu34wlRyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = rs.best_estimator_\n",
        "\n",
        "y_pred = best.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy Test:\", acc)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz_xhQdHcgyD",
        "outputId": "cf365a90-1b79-48ff-c168-5751c15636cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Test: 0.40306137184115526\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        alto       0.46      0.68      0.55     35124\n",
            "        bajo       0.42      0.57      0.48     34597\n",
            "  medio-alto       0.30      0.15      0.20     34324\n",
            "  medio-bajo       0.32      0.21      0.25     34455\n",
            "\n",
            "    accuracy                           0.40    138500\n",
            "   macro avg       0.37      0.40      0.37    138500\n",
            "weighted avg       0.37      0.40      0.37    138500\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[23838  4095  3859  3332]\n",
            " [ 5532 19844  3378  5843]\n",
            " [13890  9387  4990  6057]\n",
            " [ 8810 13941  4552  7152]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo en drive en el path definido para el output"
      ],
      "metadata": {
        "id": "IECXFL24lVWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(\n",
        "    {\n",
        "        'model': best,\n",
        "        'te_mappings': te_mappings,\n",
        "        'target': TARGET\n",
        "    },\n",
        "    OUTPUT_MODEL\n",
        ")\n",
        "\n",
        "print(\"Modelo guardado en:\", OUTPUT_MODEL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQWcQ7DZchn0",
        "outputId": "fe1b7f09-f80a-4a22-db49-131a862f5f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado en: /content/drive/MyDrive/Colab Notebooks/Introduccion IA/modelo_svm_colab.joblib\n"
          ]
        }
      ]
    }
  ]
}